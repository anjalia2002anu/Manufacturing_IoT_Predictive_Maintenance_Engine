{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9s-JjDdU7LB"
      },
      "source": [
        "## **Task 1: Feature Engineering**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ovmNw5-e-En"
      },
      "source": [
        "##### **Load & Prepare the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVfRMsdOTpy4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from joblib import dump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AiID5jo4g-QF"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jyBLeqnnh1C1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.listdir('/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcCA0OrCf7nF"
      },
      "outputs": [],
      "source": [
        "# Load training data\n",
        "df = pd.read_csv(\n",
        "    \"train_FD001.txt\",\n",
        "    sep=r\"\\s+\",\n",
        "    header=None\n",
        ") # Read the file and split columns wherever there are one or more spaces or tabs, and assume there is no header row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXxdtb54gg7S"
      },
      "outputs": [],
      "source": [
        "# Column names based on NASA documentation\n",
        "cols = (\n",
        "    [\"engine_id\", \"cycle\"] +\n",
        "    [f\"op_setting_{i}\" for i in range(1, 4)] +\n",
        "    [f\"sensor_{i}\" for i in range(1, 22)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNjKFCHNgkMe"
      },
      "outputs": [],
      "source": [
        "df.columns = cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftC2YFPzh8M_"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1zhF0taiTxP"
      },
      "source": [
        "##### **Create Remaining Useful Life (RUL)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqxeUR1HiC35"
      },
      "outputs": [],
      "source": [
        "# Max cycle per engine\n",
        "max_cycle = df.groupby(\"engine_id\")[\"cycle\"].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgvo4BsWifq7"
      },
      "outputs": [],
      "source": [
        "# Map max cycle\n",
        "df[\"max_cycle\"] = df[\"engine_id\"].map(max_cycle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h60Aq4scik2K"
      },
      "outputs": [],
      "source": [
        "# Remaining Useful Life\n",
        "df[\"RUL\"] = df[\"max_cycle\"] - df[\"cycle\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tkjh5Hcit0R"
      },
      "source": [
        "##### **Create 24-Hour Failure Label (Classification Target)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8XI9wxZio0h"
      },
      "outputs": [],
      "source": [
        "FAILURE_WINDOW = 24  # 24 hours / cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nASbnRpwizCw"
      },
      "outputs": [],
      "source": [
        "df[\"failure_next_24hrs\"] = (df[\"RUL\"] <= FAILURE_WINDOW).astype(int) # If Remaining Useful Life (RUL) ≤ 24 cycles, failure will happen within the next 24 hours"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9f0HUfoi4xH"
      },
      "outputs": [],
      "source": [
        "df[['RUL','failure_next_24hrs']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z0J8NOMjFc4"
      },
      "source": [
        "#### **Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug5-o3P6jVOu"
      },
      "source": [
        "##### **A. Rolling Mean & Standard Deviation(Last 1, 6, 12 hours)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Av1YFu9i6yf"
      },
      "outputs": [],
      "source": [
        "WINDOWS = [6, 12] # rolling time windows\n",
        "SENSORS = [f\"sensor_{i}\" for i in range(1, 22)] # list of sensor columns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why 1 is NOT included in WINDOWS = [6, 12]?\n",
        "* The rolling mean of 1 value = the value itself\n",
        "* So this feature is identical to the original sensor\n",
        "* It adds no new pattern or trend\n",
        "* Standard deviation needs at least 2 values\n",
        "* With 1 value → result is NaN"
      ],
      "metadata": {
        "id": "0iHV78y3te2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdc3QpTIiIWg"
      },
      "outputs": [],
      "source": [
        "feature_dict = {} # Collect features in a dictionary which helps to generate features WITHOUT inserting into df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tcxVedLgjjKn"
      },
      "outputs": [],
      "source": [
        "for sensor in SENSORS:\n",
        "    for w in WINDOWS:\n",
        "        feature_dict[f\"{sensor}_roll_mean_{w}\"] = (\n",
        "            df.groupby(\"engine_id\")[sensor] # Each engine has its own independent life cycle. Rolling stats are calculated only within the same engine\n",
        "              .rolling(window=w) # Look at the previous w time steps, including the current one.\n",
        "              .mean() # it captures: Overall trend & Smooths noisy sensor data\n",
        "              .reset_index(level=0, drop=True)# groupby().rolling() creates a MultiIndex. Pandas can’t assign it directly to the DataFrame .Removes the engine_id index level & Aligns values correctly with original rows\n",
        "        )\n",
        "\n",
        "        feature_dict[f\"{sensor}_roll_std_{w}\"] = (\n",
        "            df.groupby(\"engine_id\")[sensor]\n",
        "              .rolling(window=w)\n",
        "              .std() # it captures: Variability / instability & Sudden fluctuations often indicate degradation\n",
        "              .reset_index(level=0, drop=True)\n",
        "        )\n",
        "# For every sensor and every time window, it creates rolling statistical features (mean and standard deviation) separately for each engine.\n",
        "# This helps the ML model understand trends and variability in sensor behavior over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAMemCIXirkW"
      },
      "outputs": [],
      "source": [
        "rolling_features = pd.DataFrame(feature_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12TZ_rO4iy6P"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df, rolling_features], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZDDro6Wj7GI"
      },
      "source": [
        "### **B. Exponential Moving Average (EMA)**\n",
        "\n",
        "EMA gives more weight to recent sensor values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQZPKiGujeIk"
      },
      "outputs": [],
      "source": [
        "ema_features = {} # It helps to stores the generated EMA feature in a dictionary instead of directly adding it to df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjrxB1aWjwxn"
      },
      "outputs": [],
      "source": [
        "for sensor in SENSORS: # Loops through all sensor columns\n",
        "    ema_features[f\"{sensor}_ema_6\"] = (\n",
        "        df.groupby(\"engine_id\")[sensor] # Groups data by engine. Ensures EMA is calculated per engine lifecycle\n",
        "          .ewm(span=6, adjust=False) # Applies Exponential Weighted Moving Average. span=6 → recent 6 time steps get higher weight. adjust=False → uses recursive EMA formula (standard in ML & signal processing)\n",
        "          .mean() # Computes the EMA values. Despite the name, EMA is not a simple average—it weights recent values more heavily.\n",
        "          .reset_index(level=0, drop=True) # Removes the engine_id index created by groupby()\n",
        "    )\n",
        "\n",
        "    ema_features[f\"{sensor}_ema_12\"] = (\n",
        "        df.groupby(\"engine_id\")[sensor]\n",
        "          .ewm(span=12, adjust=False)\n",
        "          .mean()\n",
        "          .reset_index(level=0, drop=True)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code creates Exponential Moving Average (EMA) features for each sensor, calculated separately for each engine, using two time windows:\n",
        "\n",
        "* EMA(6) → short-term behavior\n",
        "\n",
        "* EMA(12) → medium-term behavior\n",
        "\n",
        "These features help the model detect early degradation patterns in sensor readings."
      ],
      "metadata": {
        "id": "2LX-JAYhuU5F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRF2rS0Qjvjj"
      },
      "outputs": [],
      "source": [
        "ema_df = pd.DataFrame(ema_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0Y3nvCPjzGP"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df, ema_df], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Jdd5XGkkLQf"
      },
      "source": [
        "### **C. Lag Features (t-1, t-2)**\n",
        "\n",
        "Lag features capture temporal dependency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvBs0tVjoKCS"
      },
      "source": [
        "This creates lag (historical) features for each sensor so the ML model can learn:\n",
        "\n",
        "How past sensor values influence future failures\n",
        "\n",
        "Lag features are essential in time-series prediction and prevent data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm1DPnxVkFXE"
      },
      "outputs": [],
      "source": [
        "LAGS = [1, 2] #Lag-1 → previous time step\n",
        "# Lag-2 → two time steps ago"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7rG3robnApf"
      },
      "outputs": [],
      "source": [
        "lag_features = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZX923ZtkS8t"
      },
      "outputs": [],
      "source": [
        "for sensor in SENSORS:\n",
        "    for lag in LAGS:\n",
        "        lag_features[f\"{sensor}_lag_{lag}\"] = (\n",
        "            df.groupby(\"engine_id\")[sensor]\n",
        "              .shift(lag) # Shifts sensor values backward in time & Creates historical context\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNJGsFxAnLbt"
      },
      "outputs": [],
      "source": [
        "lag_df = pd.DataFrame(lag_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mtGqwrNnPH5"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df, lag_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFJLsRPtnQN6"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxjza8r-kf_S"
      },
      "source": [
        "### **Handle Missing Values**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rolling and lag features create NaN values at the beginning of each time series.\n",
        "\n",
        "The maximum window or lag tells us how many initial rows must be dropped to remove all NaNs safely."
      ],
      "metadata": {
        "id": "AtMTkCLKIB_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WINDOW = max(max(WINDOWS), max(LAGS)) #finds the largest value among all rolling window sizes (WINDOWS) and lag steps (LAGS)"
      ],
      "metadata": {
        "id": "lAohKCTI90zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WINDOW"
      ],
      "metadata": {
        "id": "ppFLVnntu_CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.groupby(\"engine_id\").cumcount() >= MAX_WINDOW].reset_index(drop=True)\n",
        "#removes the first few rows of each engine where time-series features (rolling, lag, EMA) are not fully available.\n",
        "#cumcount():It counts rows within each group, starting from 0, and increases by 1 for every new row in that group."
      ],
      "metadata": {
        "id": "6o4C9dWh_uHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFA35t-Hkp2D"
      },
      "source": [
        "### **Select Final Feature Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDoSoC56kmcz"
      },
      "outputs": [],
      "source": [
        "FEATURE_COLUMNS = [\n",
        "    col for col in df.columns\n",
        "    if \"sensor_\" in col and\n",
        "    (\"roll\" in col or \"ema\" in col or \"lag\" in col)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4auJpRkJk0Xd"
      },
      "outputs": [],
      "source": [
        "X = df[FEATURE_COLUMNS]\n",
        "y = df[\"failure_next_24hrs\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.isna().sum().sum()"
      ],
      "metadata": {
        "id": "IYPUdw-w8jmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tnYrUFSk7q6"
      },
      "source": [
        "### **Efficient Serialization Using joblib**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlM4jbnqk3Ri"
      },
      "outputs": [],
      "source": [
        "dump(X, \"X_features_FD001.joblib\")# dump() serializes (converts) Python objects into binary files. Files are saved on disk with .joblib extension\n",
        "dump(y, \"y_labels_FD001.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MFBMuDPlKxL"
      },
      "outputs": [],
      "source": [
        "from joblib import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBkhRJERmZCe"
      },
      "outputs": [],
      "source": [
        "X = load(\"X_features_FD001.joblib\") # Reads binary .joblib files. Reconstructs the original Python objects in memory\n",
        "y = load(\"y_labels_FD001.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Task 2: Modeling**\n"
      ],
      "metadata": {
        "id": "F41ahPpmza9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "UTBC2tUS3ZkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)\n",
        "#stratify=y: Ensures failures appear in both train & test. Mandatory for <1% imbalance"
      ],
      "metadata": {
        "id": "dd4OSNuY3bOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Baseline Model: Logistic Regression**\n"
      ],
      "metadata": {
        "id": "6HZaRlBA0b8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "hSpKd2qA68Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_pipeline = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler()), #Scales all features to the same range so Logistic Regression works properly\n",
        "\n",
        "    (\"smote\", SMOTE(\n",
        "        sampling_strategy=\"auto\", #Generates synthetic samples for the minority class to balance the dataset.(applied only on training data, no data leakage).\n",
        "        random_state=42\n",
        "    )),\n",
        "\n",
        "    (\"model\", LogisticRegression(\n",
        "        max_iter=1000, #ensures convergence\n",
        "        class_weight=None, #not needed because SMOTE balances classes\n",
        "        n_jobs=-1 #uses all CPU cores for faster training\n",
        "    ))\n",
        "])"
      ],
      "metadata": {
        "id": "5yIGE8T5y_JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6hDILrDj6yXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate Logistic Regression (PR-AUC)\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
        "\n",
        "y_probs_lr = logreg_pipeline.predict_proba(X_test)[:, 1]\n",
        "pr_auc_lr = average_precision_score(y_test, y_probs_lr)\n",
        "#calculates the probability of positive class predictions and evaluates the model using precision-recall performance.\n",
        "\n",
        "print(\"Logistic Regression PR-AUC:\", pr_auc_lr)"
      ],
      "metadata": {
        "id": "6TPZdwZ67UGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Precision–Recall tradeoff (High Precision focus)**"
      ],
      "metadata": {
        "id": "aozE-w2G0Ork"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_test, y_probs_lr)\n",
        "\n",
        "pr_df = pd.DataFrame({\n",
        "    \"precision\": precision[:-1],\n",
        "    \"recall\": recall[:-1],\n",
        "    \"threshold\": thresholds\n",
        "})\n",
        "\n",
        "pr_df.sort_values(\"precision\", ascending=False).head()"
      ],
      "metadata": {
        "id": "04FjQEWe0T9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Production Model: XGBoost**"
      ],
      "metadata": {
        "id": "t1V2ZufkEUbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "lCEGQF66EyG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count class distribution\n",
        "negative_samples = (y_train == 0).sum()\n",
        "positive_samples = (y_train == 1).sum() #Counts how many non-failure (0) and failure (1) samples are in the training data.\n",
        "\n",
        "scale_pos_weight = negative_samples / positive_samples #Computes how much more weight the model should give to the rare failure class\n",
        "\n",
        "print(\"scale_pos_weight:\", scale_pos_weight)"
      ],
      "metadata": {
        "id": "OzTMX_2a3wZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_production_pipeline = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler()), #Scales numerical features so the model trains more stably\n",
        "\n",
        "    (\"model\", XGBClassifier(\n",
        "        objective=\"binary:logistic\", #binary classification with probability output\n",
        "        eval_metric=\"aucpr\", #evaluates using Precision-Recall AUC (best for imbalance)\n",
        "        scale_pos_weight=scale_pos_weight, #increases importance of rare failure class\n",
        "\n",
        "        n_estimators=400, #number of boosting trees\n",
        "        max_depth=6, #controls model complexity\n",
        "        learning_rate=0.05, #slow, stable learning\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8, #reduce overfitting\n",
        "\n",
        "        n_jobs=-1, #use all CPU cores\n",
        "        random_state=42 #reproducible results\n",
        "    ))\n",
        "])"
      ],
      "metadata": {
        "id": "Fzymx9qZ4AAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_production_pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "FTCmhGikFMyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate XGBoost\n",
        "y_pred_proba = xgb_production_pipeline.predict_proba(X_test)[:, 1] #[:, 1] selects the probability of the positive (failure) class\n",
        "\n",
        "pr_auc = average_precision_score(y_test, y_pred_proba)\n",
        "print(\"PR-AUC:\", pr_auc)"
      ],
      "metadata": {
        "id": "4HRjFmNTFPgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision–Recall Curve"
      ],
      "metadata": {
        "id": "rYvLf1AWFfl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qwGZyB-FFj4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(recall, precision, label=f\"PR-AUC = {pr_auc:.4f}\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kq2RLZiFFZsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Threshold Selection (High Precision Strategy)**\n",
        "\n",
        "selects the classification threshold that achieves ≥95% precision while maximizing recall"
      ],
      "metadata": {
        "id": "wI5jXNIx5rzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_precision = 0.95\n",
        "\n",
        "thresholds = thresholds[:len(precision)-1] #Aligns the number of thresholds with precision/recall values (PR curves return one extra precision point).\n",
        "\n",
        "valid_idx = np.where(precision[:-1] >= target_precision)[0] #Finds indices where precision is at least 0.95.\n",
        "\n",
        "best_idx = valid_idx[np.argmax(recall[valid_idx])] #Among those valid points, selects the one with the highest recall.\n",
        "\n",
        "best_threshold = thresholds[best_idx] #Gets the decision threshold corresponding to that best point.\n",
        "\n",
        "print(\"Selected threshold:\", best_threshold)\n",
        "print(\"Precision:\", precision[best_idx])\n",
        "print(\"Recall:\", recall[best_idx])"
      ],
      "metadata": {
        "id": "sW5SQCdKFozU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converts predicted probabilities into final binary class predictions using the custom threshold instead of the default 0.5.\n",
        "y_pred_custom = (y_pred_proba >= best_threshold).astype(int)"
      ],
      "metadata": {
        "id": "OqiQPIWLF8wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Evaluation Metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_custom, digits=4))"
      ],
      "metadata": {
        "id": "uhm-zjkwPkno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameter Tuning via GridSearchCV**"
      ],
      "metadata": {
        "id": "Ym4Bfm4Nl9fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import make_scorer"
      ],
      "metadata": {
        "id": "xk5K-5nnntYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Pipeline\n",
        "xgb_pipeline = Pipeline(steps=[\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"xgb\", XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        eval_metric=\"aucpr\",\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])"
      ],
      "metadata": {
        "id": "pUc7hfBgqGkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Grid\n",
        "param_grid = {\n",
        "    \"xgb__n_estimators\": [200, 400],\n",
        "    \"xgb__max_depth\": [4, 6],\n",
        "    \"xgb__learning_rate\": [0.03, 0.05],\n",
        "    \"xgb__subsample\": [0.8, 1.0],\n",
        "    \"xgb__colsample_bytree\": [0.8, 1.0]\n",
        "}"
      ],
      "metadata": {
        "id": "qAqUMdy8quTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PR-AUC Scorer:This scorer makes GridSearchCV evaluate models using PR-AUC\n",
        "pr_auc_scorer = make_scorer(  #Creates a custom scoring function for model evaluation\n",
        "    average_precision_score,\n",
        "    needs_proba=True #tells GridSearchCV to use predicted probabilities, not class labels\n",
        ")"
      ],
      "metadata": {
        "id": "LG4aBA1Gq4Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV Setup\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42) #Splits data into 3 folds.Stratified → keeps class imbalance ratio the same in each fold. shuffle=True → randomizes samples\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=xgb_pipeline,\n",
        "    param_grid=param_grid, #Tries all parameter combinations in param_grid\n",
        "    scoring=pr_auc_scorer,\n",
        "    cv=cv, #Uses stratified cross-validation\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "6DMVyT20q7rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "JKV9EydKrMsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best Parameters\n",
        "print(\"Best Parameters:\")\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "id": "Q9UciFe0rRC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Final Model (GridSearch Best)\n",
        "best_xgb_grid = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "wNeEIOXVra3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate on Test Data\n",
        "y_pred_proba = best_xgb_grid.predict_proba(X_test)[:, 1]\n",
        "\n",
        "pr_auc = average_precision_score(y_test, y_pred_proba)\n",
        "print(\"Test PR-AUC:\", pr_auc)"
      ],
      "metadata": {
        "id": "9obfKC5drjCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "man28NDQuA45"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}